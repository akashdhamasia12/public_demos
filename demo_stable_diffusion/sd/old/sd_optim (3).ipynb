{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ca6d92e7-10aa-44db-8957-e25901a96792",
   "metadata": {},
   "source": [
    "## Stable Diffusion on SPR with IPEX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ebf84a4-42f9-4c8d-ae63-f209cac19a78",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "from diffusers import AutoencoderKL, DDPMScheduler, PNDMScheduler, StableDiffusionPipeline, UNet2DConditionModel\n",
    "from diffusers.optimization import get_scheduler\n",
    "from diffusers.pipelines.stable_diffusion import StableDiffusionSafetyChecker\n",
    "\n",
    "from transformers import CLIPFeatureExtractor, CLIPTextModel, CLIPTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eba43447-9020-416a-a22f-88d9ed50fcbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Intel token\n",
    "# MY_TOKEN=\"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\"\n",
    "# My token\n",
    "MY_TOKEN='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'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1f14327-4a47-4c5d-a876-5f700f9bf33d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%env ONEDNN_VERBOSE=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b7f741b-bc0e-4d5b-a038-a8118257890a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load models and create wrapper for stable diffusion\n",
    "tokenizer = CLIPTokenizer.from_pretrained(\"CompVis/stable-diffusion-v1-4\", subfolder=\"tokenizer\", use_auth_token=MY_TOKEN)\n",
    "text_encoder = CLIPTextModel.from_pretrained(\"CompVis/stable-diffusion-v1-4\", subfolder=\"text_encoder\", use_auth_token=MY_TOKEN)\n",
    "vae = AutoencoderKL.from_pretrained(\"CompVis/stable-diffusion-v1-4\", subfolder=\"vae\", use_auth_token=MY_TOKEN)\n",
    "unet = UNet2DConditionModel.from_pretrained(\"CompVis/stable-diffusion-v1-4\", subfolder=\"unet\", use_auth_token=MY_TOKEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27a11ec4-f683-4668-87d4-19db9ba0b633",
   "metadata": {},
   "outputs": [],
   "source": [
    "import intel_extension_for_pytorch as ipex\n",
    "\n",
    "unet.eval()\n",
    "# text_encoder.eval()\n",
    "# unet = unet.to(memory_format=torch.channels_last)\n",
    "\n",
    "# unet = ipex.optimize(unet)\n",
    "\n",
    "unet = ipex.optimize(unet, dtype=torch.bfloat16)\n",
    "# text_encoder = ipex.optimize(text_encoder, dtype=torch.bfloat16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68275cc2-9cd2-4f18-8766-04baf19ada5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = StableDiffusionPipeline(\n",
    "    text_encoder=text_encoder,\n",
    "    vae=vae,\n",
    "    unet=unet,\n",
    "    tokenizer=tokenizer,\n",
    "    scheduler=PNDMScheduler(beta_start=0.00085, \n",
    "                            beta_end=0.012, \n",
    "                            beta_schedule=\"scaled_linear\", \n",
    "                            skip_prk_steps=True),\n",
    "    safety_checker=StableDiffusionSafetyChecker.from_pretrained(\"CompVis/stable-diffusion-safety-checker\"),\n",
    "    feature_extractor=CLIPFeatureExtractor.from_pretrained(\"openai/clip-vit-base-patch32\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e4d8984-0383-4479-93f9-406ed48b6c80",
   "metadata": {},
   "source": [
    "**Single image inference**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59b1f7ca-facb-44a6-8761-c206c4c5dd12",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"Painting of a frog with hat on a bicycle cycling in New York City at a beautiful dusk with a traffic jam and moody people in the style of Picasso\"\n",
    "\n",
    "# Setting seed for deterministic output\n",
    "generator = torch.Generator(\"cpu\").manual_seed(777)\n",
    "\n",
    "with torch.cpu.amp.autocast():\n",
    "    image = pipeline(prompt, num_inference_steps=50, generator=generator).images[0]\n",
    "\n",
    "image.save(\"frog_test.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aef7f3cd-7c82-4e67-bc76-45fb122b7509",
   "metadata": {},
   "source": [
    "**Batched inference**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de81bf81-a43c-486b-b8d6-c611fdd1c262",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "def image_grid(imgs, rows, cols):\n",
    "    assert len(imgs) == rows*cols\n",
    "\n",
    "    w, h = imgs[0].size\n",
    "    grid = Image.new('RGB', size=(cols*w, rows*h))\n",
    "    grid_w, grid_h = grid.size\n",
    "    \n",
    "    for i, img in enumerate(imgs):\n",
    "        grid.paste(img, box=(i%cols*w, i//cols*h))\n",
    "    return grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9aae9e2-7ba3-40b1-ae75-a83de45fa897",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_images = 3\n",
    "\n",
    "prompt = [\"Painting of a frog with hat on a bicycle cycling in New York City at a beautiful dusk with a traffic jam and moody people in the style of Picasso\"] * num_images\n",
    "\n",
    "with torch.cpu.amp.autocast():\n",
    "    images = pipeline(prompt).images\n",
    "\n",
    "grid = image_grid(images, rows=1, cols=3)\n",
    "\n",
    "grid.save(f\"frog_batch.png\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
